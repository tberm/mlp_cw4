{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a51300f-da8a-42bf-84c7-ea42fc97108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_experiment import load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa0e5b4-6e7a-4c62-b748-1d8fcd5109f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['model', 'train_layer', 'train_source', 'val_source', 'optimum_threshold', 'calibrated_acc', 'accuracy']\n",
    "results = load_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f27cb-205f-4826-af9a-41fdf9201b37",
   "metadata": {},
   "source": [
    "### 1. Does SAPLMA work to identify incorrect answers in the QA task?\n",
    "- Using (MC) QA data to train on, because it wasn't feasible for us to generate a full training set ourselves\n",
    "- Evaluating on both held out QA MC data, and on some generated answers to check that the method still works in this more realistic case\n",
    "- Are incorrect statements generated by the model harder to spot than artificial ones?\n",
    "- Does performance vary by QA subtopic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989ae39-555e-4f99-9938-5a32b42c06b6",
   "metadata": {},
   "source": [
    "#### Results when evaluating on MC answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d13fae-e547-470d-abc1-cc2306992371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_layer</th>\n",
       "      <th>train_source</th>\n",
       "      <th>val_source</th>\n",
       "      <th>optimum_threshold</th>\n",
       "      <th>calibrated_acc</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>lr</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.6002482175827026</td>\n",
       "      <td>0.8690140845070422</td>\n",
       "      <td>0.8642605633802818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>lr</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.5001144409179688</td>\n",
       "      <td>0.868838028169014</td>\n",
       "      <td>0.8679577464788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>lr</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.5951988101005554</td>\n",
       "      <td>0.858450704225352</td>\n",
       "      <td>0.856161971830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>lr</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.4912859797477722</td>\n",
       "      <td>0.8545774647887324</td>\n",
       "      <td>0.8519366197183098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.6245877146720886</td>\n",
       "      <td>0.8091549295774649</td>\n",
       "      <td>0.7959507042253521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.7086103558540344</td>\n",
       "      <td>0.8024647887323944</td>\n",
       "      <td>0.7913732394366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.6225416660308838</td>\n",
       "      <td>0.8021126760563382</td>\n",
       "      <td>0.7913732394366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>mm</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>8.314564089115326e-28</td>\n",
       "      <td>0.7737676056338029</td>\n",
       "      <td>0.6901408450704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.6882284283638</td>\n",
       "      <td>0.7709507042253521</td>\n",
       "      <td>0.691725352112676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mm</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>5.509172958403877e-35</td>\n",
       "      <td>0.7588028169014085</td>\n",
       "      <td>0.6672535211267606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>mm</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7376760563380281</td>\n",
       "      <td>0.6716549295774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>mm</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa</td>\n",
       "      <td>7.744662721467255e-39</td>\n",
       "      <td>0.5774647887323944</td>\n",
       "      <td>0.5589788732394366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  train_layer train_source val_source      optimum_threshold  \\\n",
       "60       lr        -13.0           qa         qa     0.6002482175827026   \n",
       "88       lr         -9.0           qa         qa     0.5001144409179688   \n",
       "104      lr         -5.0           qa         qa     0.5951988101005554   \n",
       "72       lr         -1.0           qa         qa     0.4912859797477722   \n",
       "97   saplma        -13.0           qa         qa     0.6245877146720886   \n",
       "5    saplma         -5.0           qa         qa     0.7086103558540344   \n",
       "45   saplma         -9.0           qa         qa     0.6225416660308838   \n",
       "87       mm        -13.0           qa         qa  8.314564089115326e-28   \n",
       "79   saplma         -1.0           qa         qa        0.6882284283638   \n",
       "13       mm         -9.0           qa         qa  5.509172958403877e-35   \n",
       "82       mm         -5.0           qa         qa                    0.0   \n",
       "99       mm         -1.0           qa         qa  7.744662721467255e-39   \n",
       "\n",
       "         calibrated_acc            accuracy  \n",
       "60   0.8690140845070422  0.8642605633802818  \n",
       "88    0.868838028169014  0.8679577464788732  \n",
       "104   0.858450704225352   0.856161971830986  \n",
       "72   0.8545774647887324  0.8519366197183098  \n",
       "97   0.8091549295774649  0.7959507042253521  \n",
       "5    0.8024647887323944  0.7913732394366197  \n",
       "45   0.8021126760563382  0.7913732394366197  \n",
       "87   0.7737676056338029  0.6901408450704225  \n",
       "79   0.7709507042253521   0.691725352112676  \n",
       "13   0.7588028169014085  0.6672535211267606  \n",
       "82   0.7376760563380281  0.6716549295774648  \n",
       "99   0.5774647887323944  0.5589788732394366  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\n",
    "    (results.train_source == 'qa')\n",
    "    & (results.val_source == 'qa')\n",
    "    & (results.val_topic.isin(['None', 'NaN']))\n",
    "][cols].sort_values('calibrated_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc16d9c-ab8b-412f-aef5-b8ee1571d073",
   "metadata": {},
   "source": [
    "- LR does better than SAPLMA across all layers! Why?\n",
    "- Results get slightly better as you go deeper. Though the difference is very minimal once you go beyond the last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a331fb7-e206-4dcf-ad0d-145666c75fbc",
   "metadata": {},
   "source": [
    "#### Results when evaluating on generated answers\n",
    "\n",
    "**NOTE** the generated answers are ~57% true! Unsure if we can just state this when reporting our results or whether we should make some adjustment / balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135f173c-be35-4eca-add5-6aa94ed8efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_layer</th>\n",
       "      <th>train_source</th>\n",
       "      <th>val_source</th>\n",
       "      <th>optimum_threshold</th>\n",
       "      <th>calibrated_acc</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mm</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>1.5063328567479166e-25</td>\n",
       "      <td>0.7527539779681762</td>\n",
       "      <td>0.6401468788249693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.5229383707046509</td>\n",
       "      <td>0.7515299877600979</td>\n",
       "      <td>0.7471236230110158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>lr</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.6722432374954224</td>\n",
       "      <td>0.747858017135863</td>\n",
       "      <td>0.7439412484700123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lr</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.8213123083114624</td>\n",
       "      <td>0.7422276621787025</td>\n",
       "      <td>0.7287637698898408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mm</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>6.778570251991412e-35</td>\n",
       "      <td>0.7405140758873929</td>\n",
       "      <td>0.5850673194614443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>lr</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.8011077046394348</td>\n",
       "      <td>0.7358629130966952</td>\n",
       "      <td>0.7307221542227662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.5588269233703613</td>\n",
       "      <td>0.7321909424724602</td>\n",
       "      <td>0.7091799265605875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.5656270980834961</td>\n",
       "      <td>0.7309669522643819</td>\n",
       "      <td>0.7118727050183598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>lr</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.5834947228431702</td>\n",
       "      <td>0.7297429620563036</td>\n",
       "      <td>0.7272949816401468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.4230741858482361</td>\n",
       "      <td>0.7260709914320687</td>\n",
       "      <td>0.6952264381884945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>mm</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>1.801960187529866e-37</td>\n",
       "      <td>0.6927784577723378</td>\n",
       "      <td>0.543451652386781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mm</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>qa</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5006119951040392</td>\n",
       "      <td>0.4651162790697675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  train_layer train_source val_source       optimum_threshold  \\\n",
       "18      mm        -13.0           qa     qa-gen  1.5063328567479166e-25   \n",
       "77  saplma        -13.0           qa     qa-gen      0.5229383707046509   \n",
       "64      lr         -5.0           qa     qa-gen      0.6722432374954224   \n",
       "40      lr         -9.0           qa     qa-gen      0.8213123083114624   \n",
       "14      mm         -9.0           qa     qa-gen   6.778570251991412e-35   \n",
       "65      lr        -13.0           qa     qa-gen      0.8011077046394348   \n",
       "98  saplma         -5.0           qa     qa-gen      0.5588269233703613   \n",
       "41  saplma         -9.0           qa     qa-gen      0.5656270980834961   \n",
       "61      lr         -1.0           qa     qa-gen      0.5834947228431702   \n",
       "31  saplma         -1.0           qa     qa-gen      0.4230741858482361   \n",
       "94      mm         -5.0           qa     qa-gen   1.801960187529866e-37   \n",
       "23      mm         -1.0           qa     qa-gen                     0.0   \n",
       "\n",
       "        calibrated_acc            accuracy  \n",
       "18  0.7527539779681762  0.6401468788249693  \n",
       "77  0.7515299877600979  0.7471236230110158  \n",
       "64   0.747858017135863  0.7439412484700123  \n",
       "40  0.7422276621787025  0.7287637698898408  \n",
       "14  0.7405140758873929  0.5850673194614443  \n",
       "65  0.7358629130966952  0.7307221542227662  \n",
       "98  0.7321909424724602  0.7091799265605875  \n",
       "41  0.7309669522643819  0.7118727050183598  \n",
       "61  0.7297429620563036  0.7272949816401468  \n",
       "31  0.7260709914320687  0.6952264381884945  \n",
       "94  0.6927784577723378   0.543451652386781  \n",
       "23  0.5006119951040392  0.4651162790697675  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\n",
    "    (results.train_source == 'qa')\n",
    "    & (results.val_source == 'qa-gen')\n",
    "    & (results.val_topic.isin(['None', 'NaN']))\n",
    "][cols].sort_values('calibrated_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b5276-fa53-4564-ae8b-fba6de382481",
   "metadata": {},
   "source": [
    "- MM getting the best calibrated acc score is kinda crazy -- it's using a threshold of 1e-25. We might want to look into this result more. Is it actually quite a good method but its confidence is incredibly uncalibrated?\n",
    "- SAPLMA and LR more evenly matched now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9c8e7-dd99-4006-8412-5b2f015b9512",
   "metadata": {},
   "source": [
    "#### Comparison of MC and generative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38f04982-bb53-4209-a9c3-7eee4509efa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_layer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>calibrated_acc</th>\n",
       "      <th>gen_accuracy</th>\n",
       "      <th>gen_cal_acc</th>\n",
       "      <th>acc_diff</th>\n",
       "      <th>cal_acc_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.8642605633802818</td>\n",
       "      <td>0.8690140845070422</td>\n",
       "      <td>0.7307221542227662</td>\n",
       "      <td>0.7358629130966952</td>\n",
       "      <td>0.133538</td>\n",
       "      <td>0.133151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.8679577464788732</td>\n",
       "      <td>0.868838028169014</td>\n",
       "      <td>0.7287637698898408</td>\n",
       "      <td>0.7422276621787025</td>\n",
       "      <td>0.139194</td>\n",
       "      <td>0.126610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.856161971830986</td>\n",
       "      <td>0.858450704225352</td>\n",
       "      <td>0.7439412484700123</td>\n",
       "      <td>0.747858017135863</td>\n",
       "      <td>0.112221</td>\n",
       "      <td>0.110593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.8519366197183098</td>\n",
       "      <td>0.8545774647887324</td>\n",
       "      <td>0.7272949816401468</td>\n",
       "      <td>0.7297429620563036</td>\n",
       "      <td>0.124642</td>\n",
       "      <td>0.124835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mm</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.6901408450704225</td>\n",
       "      <td>0.7737676056338029</td>\n",
       "      <td>0.6401468788249693</td>\n",
       "      <td>0.7527539779681762</td>\n",
       "      <td>0.049994</td>\n",
       "      <td>0.021014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mm</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.6672535211267606</td>\n",
       "      <td>0.7588028169014085</td>\n",
       "      <td>0.5850673194614443</td>\n",
       "      <td>0.7405140758873929</td>\n",
       "      <td>0.082186</td>\n",
       "      <td>0.018289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mm</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.6716549295774648</td>\n",
       "      <td>0.7376760563380281</td>\n",
       "      <td>0.543451652386781</td>\n",
       "      <td>0.6927784577723378</td>\n",
       "      <td>0.128203</td>\n",
       "      <td>0.044898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mm</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5589788732394366</td>\n",
       "      <td>0.5774647887323944</td>\n",
       "      <td>0.4651162790697675</td>\n",
       "      <td>0.5006119951040392</td>\n",
       "      <td>0.093863</td>\n",
       "      <td>0.076853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.7959507042253521</td>\n",
       "      <td>0.8091549295774649</td>\n",
       "      <td>0.7471236230110158</td>\n",
       "      <td>0.7515299877600979</td>\n",
       "      <td>0.048827</td>\n",
       "      <td>0.057625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.7913732394366197</td>\n",
       "      <td>0.8021126760563382</td>\n",
       "      <td>0.7118727050183598</td>\n",
       "      <td>0.7309669522643819</td>\n",
       "      <td>0.079501</td>\n",
       "      <td>0.071146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.7913732394366197</td>\n",
       "      <td>0.8024647887323944</td>\n",
       "      <td>0.7091799265605875</td>\n",
       "      <td>0.7321909424724602</td>\n",
       "      <td>0.082193</td>\n",
       "      <td>0.070274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.691725352112676</td>\n",
       "      <td>0.7709507042253521</td>\n",
       "      <td>0.6952264381884945</td>\n",
       "      <td>0.7260709914320687</td>\n",
       "      <td>-0.003501</td>\n",
       "      <td>0.044880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  train_layer            accuracy      calibrated_acc  \\\n",
       "0       lr        -13.0  0.8642605633802818  0.8690140845070422   \n",
       "1       lr         -9.0  0.8679577464788732   0.868838028169014   \n",
       "2       lr         -5.0   0.856161971830986   0.858450704225352   \n",
       "3       lr         -1.0  0.8519366197183098  0.8545774647887324   \n",
       "4       mm        -13.0  0.6901408450704225  0.7737676056338029   \n",
       "5       mm         -9.0  0.6672535211267606  0.7588028169014085   \n",
       "6       mm         -5.0  0.6716549295774648  0.7376760563380281   \n",
       "7       mm         -1.0  0.5589788732394366  0.5774647887323944   \n",
       "8   saplma        -13.0  0.7959507042253521  0.8091549295774649   \n",
       "9   saplma         -9.0  0.7913732394366197  0.8021126760563382   \n",
       "10  saplma         -5.0  0.7913732394366197  0.8024647887323944   \n",
       "11  saplma         -1.0   0.691725352112676  0.7709507042253521   \n",
       "\n",
       "          gen_accuracy         gen_cal_acc  acc_diff  cal_acc_diff  \n",
       "0   0.7307221542227662  0.7358629130966952  0.133538      0.133151  \n",
       "1   0.7287637698898408  0.7422276621787025  0.139194      0.126610  \n",
       "2   0.7439412484700123   0.747858017135863  0.112221      0.110593  \n",
       "3   0.7272949816401468  0.7297429620563036  0.124642      0.124835  \n",
       "4   0.6401468788249693  0.7527539779681762  0.049994      0.021014  \n",
       "5   0.5850673194614443  0.7405140758873929  0.082186      0.018289  \n",
       "6    0.543451652386781  0.6927784577723378  0.128203      0.044898  \n",
       "7   0.4651162790697675  0.5006119951040392  0.093863      0.076853  \n",
       "8   0.7471236230110158  0.7515299877600979  0.048827      0.057625  \n",
       "9   0.7118727050183598  0.7309669522643819  0.079501      0.071146  \n",
       "10  0.7091799265605875  0.7321909424724602  0.082193      0.070274  \n",
       "11  0.6952264381884945  0.7260709914320687 -0.003501      0.044880  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_res = results[\n",
    "    (results.train_source == 'qa')\n",
    "    & (results.val_source == 'qa')\n",
    "    & (results.val_topic.isin(['None', 'NaN']))\n",
    "].sort_values(['model', 'train_layer']).reset_index()\n",
    "\n",
    "gen_res = results[\n",
    "    (results.train_source == 'qa')\n",
    "    & (results.val_source == 'qa-gen')\n",
    "    & (results.val_topic.isin(['None', 'NaN']))\n",
    "].sort_values(['model', 'train_layer']).reset_index()\n",
    "\n",
    "mc_res['gen_accuracy'] = gen_res.accuracy\n",
    "mc_res['gen_cal_acc'] = gen_res.calibrated_acc\n",
    "mc_res['acc_diff'] = mc_res.accuracy.astype(float) - gen_res.accuracy.astype(float)\n",
    "mc_res['cal_acc_diff'] = mc_res.calibrated_acc.astype(float) - gen_res.calibrated_acc.astype(float)\n",
    "mc_res[['model', 'train_layer', 'accuracy', 'calibrated_acc', 'gen_accuracy', 'gen_cal_acc', 'acc_diff', 'cal_acc_diff']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0018edc-a16a-4709-a5cc-c95fd78763b6",
   "metadata": {},
   "source": [
    "- LR consistently suffers more from switching to the generated answers compared to SAPLMA (change of 0.11-0.14 vs 0-0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3eee8-a291-4f84-b2ca-33dbc943b3cc",
   "metadata": {},
   "source": [
    "### 2. Are the models identifying truth? Can they generalise between QA and simple true/false datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ce06a-dd5a-4991-81ac-4fe770cf9643",
   "metadata": {},
   "source": [
    "#### Train on true/false, evaluate on QA gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfb609f3-1d64-43e5-8546-7c36b0083c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_layer</th>\n",
       "      <th>train_source</th>\n",
       "      <th>val_source</th>\n",
       "      <th>optimum_threshold</th>\n",
       "      <th>calibrated_acc</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.4979552626609802</td>\n",
       "      <td>0.6793145654834761</td>\n",
       "      <td>0.6558139534883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.48547640442848206</td>\n",
       "      <td>0.6621787025703794</td>\n",
       "      <td>0.6178702570379437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.4913727343082428</td>\n",
       "      <td>0.6602203182374542</td>\n",
       "      <td>0.6506731946144431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>lr</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.608629584312439</td>\n",
       "      <td>0.6271725826193391</td>\n",
       "      <td>0.6181150550795593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mm</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>8.762726366740026e-08</td>\n",
       "      <td>0.6266829865361077</td>\n",
       "      <td>0.572827417380661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>lr</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.13248048722743988</td>\n",
       "      <td>0.609547123623011</td>\n",
       "      <td>0.583108935128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>lr</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.08180037885904312</td>\n",
       "      <td>0.6090575275397796</td>\n",
       "      <td>0.5351285189718482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lr</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.013107423670589924</td>\n",
       "      <td>0.5880048959608323</td>\n",
       "      <td>0.5385556915544676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>mm</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>1.74934020431241e-22</td>\n",
       "      <td>0.5789473684210527</td>\n",
       "      <td>0.5630354957160343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>mm</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>2.704772896322538e-06</td>\n",
       "      <td>0.5777233782129743</td>\n",
       "      <td>0.5507955936352509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>saplma</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>0.47811359167099</td>\n",
       "      <td>0.5769889840881273</td>\n",
       "      <td>0.5708690330477356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mm</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>tf</td>\n",
       "      <td>qa-gen</td>\n",
       "      <td>7.128925290089683e-07</td>\n",
       "      <td>0.576499388004896</td>\n",
       "      <td>0.4834761321909425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  train_layer train_source val_source      optimum_threshold  \\\n",
       "0   saplma        -13.0           tf     qa-gen     0.4979552626609802   \n",
       "29  saplma         -9.0           tf     qa-gen    0.48547640442848206   \n",
       "49  saplma         -5.0           tf     qa-gen     0.4913727343082428   \n",
       "76      lr         -5.0           tf     qa-gen      0.608629584312439   \n",
       "32      mm         -5.0           tf     qa-gen  8.762726366740026e-08   \n",
       "90      lr         -9.0           tf     qa-gen    0.13248048722743988   \n",
       "85      lr        -13.0           tf     qa-gen    0.08180037885904312   \n",
       "17      lr         -1.0           tf     qa-gen   0.013107423670589924   \n",
       "80      mm         -1.0           tf     qa-gen   1.74934020431241e-22   \n",
       "52      mm         -9.0           tf     qa-gen  2.704772896322538e-06   \n",
       "93  saplma         -1.0           tf     qa-gen       0.47811359167099   \n",
       "48      mm        -13.0           tf     qa-gen  7.128925290089683e-07   \n",
       "\n",
       "        calibrated_acc            accuracy  \n",
       "0   0.6793145654834761  0.6558139534883721  \n",
       "29  0.6621787025703794  0.6178702570379437  \n",
       "49  0.6602203182374542  0.6506731946144431  \n",
       "76  0.6271725826193391  0.6181150550795593  \n",
       "32  0.6266829865361077   0.572827417380661  \n",
       "90   0.609547123623011   0.583108935128519  \n",
       "85  0.6090575275397796  0.5351285189718482  \n",
       "17  0.5880048959608323  0.5385556915544676  \n",
       "80  0.5789473684210527  0.5630354957160343  \n",
       "52  0.5777233782129743  0.5507955936352509  \n",
       "93  0.5769889840881273  0.5708690330477356  \n",
       "48   0.576499388004896  0.4834761321909425  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\n",
    "    (results.train_source == 'tf')\n",
    "    & (results.val_source == 'qa-gen')\n",
    "    & (results.val_topic.isin(['None', 'NaN']))\n",
    "][cols].sort_values('calibrated_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e9f10-67ee-4905-89c9-c5c94e921622",
   "metadata": {},
   "source": [
    "- SAPLMA now quite a bit better than LR.\n",
    "- In terms of standard accuracy (0.5 threshold), only results that are better than always guessing True are SAPLMA layers -5..-13 and LR layer -5\n",
    "- This is completely at odds with Alex Mallen's (Google Doc) results that a linear probe solved problems with the NN in generalising to different kinds of statement (negated ones).\n",
    "- I wonder if we should try doing what Mallen does and seeing if we get the same or different? (train on true/false no negations, evaluate on true/false negations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e2ed9-4753-401f-8a6f-bb896a65c23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
